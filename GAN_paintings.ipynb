{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sIz_YB6tuw_3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-13 14:16:07.086276: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-13 14:16:07.179228: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-12-13 14:16:07.626256: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/fpserver/anaconda3/envs/tf/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-11.7/lib64:\n",
            "2022-12-13 14:16:07.626302: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/fpserver/anaconda3/envs/tf/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-11.7/lib64:\n",
            "2022-12-13 14:16:07.626306: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Reshape, Conv2D, Conv2DTranspose, Dropout\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PN7IOqIVvHeK"
      },
      "outputs": [],
      "source": [
        "reshape_size = (256,256)\n",
        "root_dir = \"/media/fpserver/New Volume/DATASETS/van_gogh/VincentVanGogh\"\n",
        "\n",
        "i = 0\n",
        "for dir in os.listdir(root_dir):\n",
        "  for imgfile in os.listdir(os.path.join(root_dir, dir)):\n",
        "    \n",
        "    img = cv2.imread(root_dir + \"/\" + dir + \"/\" + imgfile)\n",
        "    if img is None:\n",
        "      print(\"wrong path\")\n",
        "    else:\n",
        "      img = cv2.resize(img, reshape_size)\n",
        "      cv2.imwrite(f\"/media/fpserver/New Volume/DATASETS/van_gogh/resized/{i}.png\", img)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5AVlyqzvl9Q",
        "outputId": "4cf0b801-1bdc-4ec7-c96b-512a93fbabef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2025"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(os.listdir(\"/media/fpserver/New Volume/DATASETS/van_gogh/resized\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2BNgsZDzy7Gu"
      },
      "outputs": [],
      "source": [
        "#parameters\n",
        "\n",
        "img_width = 256\n",
        "img_height = 256\n",
        "channels = 3\n",
        "img_shape = (img_width, img_height, channels)\n",
        "latent_dim = 100\n",
        "adam = Adam(0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxx88T4DzQTt",
        "outputId": "4f024e9f-b3bf-4f48-9670-45a26f3bdfc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 262144)            26476544  \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 262144)            0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 64, 64, 128)      524416    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 128, 128, 128)    262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 256, 256, 128)    262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 256, 256, 128)     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 256, 256, 3)       3459      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,528,963\n",
            "Trainable params: 27,528,963\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-13 14:16:22.687326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-13 14:16:22.728032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-13 14:16:22.728175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-13 14:16:22.729044: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-13 14:16:22.729497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-13 14:16:22.729608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-13 14:16:22.729700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-13 14:16:23.228467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-13 14:16:23.228823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-13 14:16:23.228926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-13 14:16:23.229015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21838 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "#generator\n",
        "def build_generator():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(256 * 32 * 32, input_dim=latent_dim))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Reshape((32,32,256)))\n",
        "\n",
        "  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(3, (3,3), activation=\"tanh\", padding=\"same\"))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "generator = build_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7vIV3ou0Sf0",
        "outputId": "bd8801b2-c65b-4352-ad38-8b4011cc949f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 64)      1792      \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 256, 256, 64)      0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 256, 256, 128)     73856     \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 256, 256, 128)     0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 256, 256, 128)     147584    \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 256, 256, 128)     0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 256, 256, 256)     295168    \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 256, 256, 256)     0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16777216)          0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16777216)          0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 16777217  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,295,617\n",
            "Trainable params: 17,295,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_discriminator():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3,3), padding=\"same\", input_shape=img_shape))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(256, (3,3), padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mus9Bk3h2r9G"
      },
      "outputs": [],
      "source": [
        "GAN = Sequential()\n",
        "discriminator.trainable = False\n",
        "GAN.add(generator)\n",
        "GAN.add(discriminator)\n",
        "GAN.compile(loss=\"binary_crossentropy\", optimizer=adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kmIziJcA2z7Y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import imageio\n",
        "import PIL\n",
        "\n",
        "save_name = 0.00000000\n",
        "\n",
        "def save_imgs(epoch):\n",
        "    r, c = 2, 2\n",
        "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    global save_name\n",
        "    save_name += 0.00000001\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = (gen_imgs + 1) / 2.0\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt])\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    #fig.savefig(\"currentgeneration.png\")\n",
        "    fig.savefig(\"/media/fpserver/New Volume/DATASETS/van_gogh/generated/%.8f.png\" % save_name)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCbwreTC2_ip",
        "outputId": "4b0bf9d1-6c04-414b-fe58-4e3486e9c55e"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def train(epochs, batch_size=32, save_interval=200):\n",
        "\n",
        "  array = []\n",
        "  #PUT PATH OF RESIZED IMAGES\n",
        "  path = \"/media/fpserver/New Volume/DATASETS/van_gogh/some/\"\n",
        "\n",
        "  for dir in os.listdir(path):\n",
        "            # print(dir)\n",
        "    image = Image.open(path + dir)\n",
        "    data = np.asarray(image)\n",
        "    array.append(data)\n",
        "\n",
        "  X_train = np.array(array)\n",
        "  print(X_train.shape)\n",
        "\n",
        "  # print(X_train.shape)\n",
        "  #Rescale data between -1 and 1\n",
        "  X_train = X_train / 127.5 -1.\n",
        "  bat_per_epo = int(X_train.shape[0] / batch_size)\n",
        "  # X_train = np.expand_dims(X_train, axis=3)\n",
        "  print(X_train.shape)\n",
        "\n",
        "  #Create our Y for our Neural Networks\n",
        "  valid = np.ones((batch_size, 1))\n",
        "  fakes = np.zeros((batch_size, 1))\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for j in range(bat_per_epo):\n",
        "      #Get Random Batch\n",
        "      idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "      imgs = X_train[idx]\n",
        "\n",
        "      #Generate Fake Images\n",
        "      noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "      gen_imgs = generator.predict(noise)\n",
        "\n",
        "      #Train discriminator\n",
        "      d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "      d_loss_fake = discriminator.train_on_batch(gen_imgs, fakes)\n",
        "      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "      noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "      \n",
        "      #inverse y label\n",
        "      g_loss = GAN.train_on_batch(noise, valid)\n",
        "\n",
        "      print(\"******* %d %d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch,j, d_loss[0], 100* d_loss[1], g_loss))\n",
        "\n",
        "      # if(epoch % save_interval) == 0:\n",
        "    save_imgs(epoch)\n",
        "\n",
        "\n",
        "train(10000, batch_size=32, save_interval=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMnYMz2t3S86"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('tf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f700c8a64fc88612d0c7f5a024d27ff5ba2cd1b646a15db87e4f733a65742107"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
